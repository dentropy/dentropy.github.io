---
uuid: dc6a1ac7-60f0-452d-9536-9fed6d92bc51
share: true
title: Roadmap - Discord Binding
---
## Directory

* [Discord Binding](/1c376bfd-75ef-4c0d-9e23-3680653de55f)
* [Logs - Discord Binding](/undefined) - Private
- [DAO Auditing via Discord Logs - Private](/undefined)
- [DAO Auditing via Discord - Brainstorming - Private](/undefined)
## Next Steps

* Add all queries from [Questions for Discord Data](/46abc67b-bbe7-4800-82f5-f08d4c457ef0) to queries.py and test them
* Review all graph's completed so far
* Frontend - Add padding on the drawer component
* [Discord Binding Interviews](/undefined) - Private

## TODO

* Priority
	* [Make a video recording ddaemon discord binding what I got so far](/undefined)
	* Jupyter Notebook Report I can send people as PDF and HTML
	* **REMEMBER TODO EXAMPLE INVESTIGATION**
	* **Do a demo for someone else**
	* **SHIP SOMETHING**
* Documentation + Writing
	* [Discord Scraping Procedures](/dc48a7b7-34e6-4113-bdeb-c655cf2da186)
	* SQL vs NoSQL blog post
	* Postgres to DuckDB/CSV Tutorial
	* Benchmark everything and write a blog post
		* Generate Synthetic Dataset / Get Permission to use a guild as a public dataset
	* Blog post on the ETL pipeline
		* Aggregations would be much harder, stay with SQL till the end
	* Question Database with Embeddings
	* When do we start tagging the messages?
	* We need systems of tags that are composable
	* We want to be able to segment the data into contextualized conversations
		* Segment by time block
	* Just build the dam discord binding dashboard
		* [Graph all the SQL queries for Discord Data from for who is worth getting to know and how to get to know them](/undefined)
	* Better Unit Testing, PyTest, and document it
		* Better Logging throughout the application, write out control flow logic
		* Add descriptions too all the functions
	* Complete all the TODO queries in [Questions for Discord Data](/46abc67b-bbe7-4800-82f5-f08d4c457ef0)
	* Spark Binding
* Research and Interviews
	* [Discord Binding Interviews](/undefined) - Private
* [Backlog - Discord Scraping](/undefined)
	* Develop a Bot
	* Document Discord Scraping Procedure
	* NEED TO RENAME FOLDERS AFTER GUILD_ID
	* Write script that get the GUILD_ID from either sqlite or the database itself
		* Have a python script take in the arguments from a JSON file and log everything that is important
	* [Discord Scraping Data Migration, Proper SQL Tables not just JSON](/undefined)
	* [Discord Scraping Procedures](/dc48a7b7-34e6-4113-bdeb-c655cf2da186)
	* [Backlog - Discord Scraping](/undefined) - Private
	* [Discord Scraping Logs](/undefined) - Private
* Discord ETL - Base
	* message_urls_t needs guilds_t, author_guild_id, and channel_id
	* [What discord author was mentioned the most?](/02996ff2-f55e-4eae-a4b6-15d042b92896)
	* JSON SQL Validator
	* JSON Neo4J Validator
	* Job Queue for Queries
	* I need to test mentions
	* [Discord Binding Fix Roles Bug](/undefined)
	* [Add Constraints for  Authors_t Attachments_t and Roles_t for DAO Auditing via Discord project](/undefined)
	* Add Constraints to all Tables
	* Postgres to SQLite Research, Tutorial, and Script
		* Learn [How to dump from Postgres to SQLite?](/undefined)
		* Learn [How to dump Postgres to CSV?](/undefined)
	* Index all S3 objects to key value store
	* Review [Graph QL Alchemy](/undefined)
	* Come up with all the Cypher Queries we should do
	* ETL Backlog
		* Test requirements.txt
		* Make URL indexing optional via environment variable
		* Separate the database indexing code, search insert files
		* Add Constraints Retroactively
			* Add missing SQL constraints
			* Figure out how to add data that is missing into the database
			* https://chat.openai.com/share/53ed5b7b-95b6-4a08-ae16-417b272d749b
		* Guild Specific Indexing from S3 and file system data
		* Validate all data is ingested correctly and effectively, manually, have scripts test json files for data in database
		* Optimize Roles indexing
		* messages_urls_tables
			* SQL Alchemy indexing data
		* Reply Table
			* SQL Alchemy indexing data
			* Neo4J indexing Data
			* For SQL Alchemy rather than doing upsert do insert, so do a select first manually so no postgres native stuff is there
		* Neo4j Specific
			* Emoji Nodes
			* Use author nodes not author_guild_id nodes
* [NLP on Discord Data](/undefined)
	* Named Entity Recognition in Graph Database
	* Label the Channels according to a schema, for example which channel is Announcements
	* Question Extraction
	* Write
		* Explain how I want to annotate my raindrop and hypothesis
	* Wikipedia / Wikidata Schema
	* Intent Description UI, we need to be able to do query and then provide description of what we see
	* Research prompts to use for labeling users and their data, write multiple blog posts
	* We need to come up with a long list of questions for each DAO
* queries.py - Base Queries
	* [Questions for Discord Data](/46abc67b-bbe7-4800-82f5-f08d4c457ef0)
	* [Queries Implemented in queries.py](/undefined)
	* Check for is_bot in a bunch of the queries
* querys.py - Caching Job Service
	* Create a file for this
		* Do we want to use a module for this or develop an API
		* We should be able to do both, just send JSON back and forth
* graphs.py
* Backend
	* Hire a Mentor to tell me which Python API is best
		* Should we use [FastAPI](/undefined)
		* Should we use [Flask-SQLAlchemy](/undefined)
	* Dockerize
	* Query Caching using IndexedDB
	* Use Discord ETL, Job Queue
	* Use Discord ETL, Index all S3 objects to key value store
	* Document API, OpenAPI
	* Come up with tags and collections for tags
	* History of Queries
	* Manual Labeling Data
	* Brainstorming Labels and Buckets for the data
* Frontend
	* Data Visualization Component
		* Datagrid Compnent that takes Pandas JSON
* Long Term
	* Additional Data Sources ETL, Create a schema for twitter and youtube data for indexing profiles and other metadata about content


## Completed [2023-12-03](/undefined)

* [Research Example Project Roadmaps](/e56b849c-2f2f-42cf-83a1-ba42a5a9cf57)
* Updated [Roadmap - Discord Binding](/dc6a1ac7-60f0-452d-9536-9fed6d92bc51)
	* Updated `ETL Diagram`
		* Don't use JSON tables anymore
		* Neo4J was added
	* Created `Application Dependency Diagram`
## Completed [2023-12-02](/undefined)

* Conducted interview on Fiverr
## Completed [2023-11-30](/undefined)

* plotly_graph API Endpoint that returns Plotly JSON
* list_graphs API endpoint to return graph's and their data
* Plotly component for react frontend
* SelectDataVisualization react component
	* Fetch data from /list_graphs
	* Update Context with Data Visualization metadata from /list_graphs
* Use context updated from SelectDataVisualization to in PlotlyGraph react component
	* Fetch data from /plotly_graphs 
	* Render data from /plotly_graphs in react

## Completed [2023-11-29](/undefined)

* React setup
	* Appbar
	* Drawer
	* Select Guild, Channel, Author Component
	* Context Setup
	* Proxy
* Plotly Graph Python Module and Graph Jupyter Notebook
	* One graph complete many more to go

## Completed [2023-11-28](/undefined)

* Tested Django REST Framework, decided not to use it
	* Create example REST API with hard coded responses
	* Get basic endpoint query working and returning data from database
	* Write basic tests for API
* Django API returns queries.py data

## Completed [2023-11-27](/undefined)

* Got core set of queries running in queries.py and run _test_queries.py
* Have script to just create the SQL schema
* Tested constraints and added more
* URL + Domain Extraction
* Script to retroactively add some constraints
* added URLs class to SQLAlchemy orm
* Neo4J now indexes URL's and Domains

## Completed [2023-11-23](/undefined)

* Reply data is not parsed from JSON
* count column name in reactions_t should be reaction_count
* rename content as msg_conent in messages_t
* rename content_length as msg_content_length in messages_t
* Create a directory for Logs
* CSV for Analytics files need their own directory
* Fix the last couple weird column_names that don't use underscores
	* Fixed guilds_t.iconUrl to icon_url
	* Fixed messages_t.isPinned to be is_pinned
* Test ORM on Native Postgres loaded queries
* SQLALchemy add the reply Class
* Neomodel for Neo4J classes complete
* Ingest of most data into neo4j complete