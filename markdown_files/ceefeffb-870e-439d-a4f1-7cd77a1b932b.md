---
uuid: ceefeffb-870e-439d-a4f1-7cd77a1b932b
share: true
title: LLM Token Tests
---
* [How many tokens per second do you guys get with GPUs like 3090 or 4090? (rtx 3060 12gb owner here) : LocalLLaMA](https://old.reddit.com/r/LocalLLaMA/comments/13j5cxf/how_many_tokens_per_second_do_you_guys_get_with/)
* [Discuss GPU configs | Why do I get 40 tokens / sec on a rtx 3060!? : LocalLLaMA](https://old.reddit.com/r/LocalLLaMA/comments/137x4qg/discuss_gpu_configs_why_do_i_get_40_tokens_sec_on/)
* [Powerful Budget AI-Workstation Build Guide (48 GB VRAM @ $1.1k) : LocalLLaMA](https://old.reddit.com/r/LocalLLaMA/comments/17phkwi/powerful_budget_aiworkstation_build_guide_48_gb/)
* [Stable Diffusion Benchmarks: 45 Nvidia, AMD, and Intel GPUs Compared | Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/stable-diffusion-benchmarks)
* [RtAnnCQxaVJNYgA4LbBhuJ.png (1921×1441)](https://cdn.mos.cms.futurecdn.net/RtAnnCQxaVJNYgA4LbBhuJ.png)
* [Magic-AI-Wiki/Wiki/Budget-AI-Workstation-Build.md at main · magiccodingman/Magic-AI-Wiki](https://github.com/magiccodingman/Magic-AI-Wiki/blob/main/Wiki/Budget-AI-Workstation-Build.md)