---
uuid: 0a62e9d5-68ae-41a5-8bdb-7773b59abc1f
share: true
title: ETL to QE, GPU accelerated Topic Modelling
---
Date: [2023-10-19](/2023-10-19)

See [Discord Binding](/1c376bfd-75ef-4c0d-9e23-3680653de55f) for project context,

## [BERTopic](/921f783a-f1bd-4317-b45f-493fe41651da) on AMD GPU using [ROCm](/915f6439-7628-438f-be14-1169ee4f6666)

## Testing [Bertopic](/921f783a-f1bd-4317-b45f-493fe41651da) Run times and Results 

On [Intel i7-9700](/Intel i7-9700) : 673.2816 Seconds
On T4 on [Google Colab](/a08c6865-0c6e-4709-8698-c07e465464c7): 80.7281 Seconds
Cohere API: 358.6873 Seconds and 35 cents USD, 3,534,005 Calls
GTX 1060 6Gb: 75.4157 Seconds

For additional context check out, [What is the length of the Bertopic default dataset from sklearn?](/7b81aadb-d7cd-4afa-8c16-4402e8ce19d5)

*CPU Script*

``` python
from bertopic import BERTopic
from sklearn.datasets import fetch_20newsgroups
import timeit
 
docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']

topic_model = BERTopic()
start_time = timeit.default_timer()
topics, probs = topic_model.fit_transform(docs)
elapsed = timeit.default_timer() - start_time
```

*Google Colab T4 Script*

``` python
!pip install bertopic
import timeit
from bertopic import BERTopic
from sklearn.datasets import fetch_20newsgroups
topic_model = BERTopic(embedding_model="all-MiniLM-L6-v2")
docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']

# topic_model = BERTopic()
start_time = timeit.default_timer()
topics, probs = topic_model.fit_transform(docs)
elapsed = timeit.default_timer() - start_time
```

*Cohere API Script (Requires Production API Key) - COSTS $0.35 USD*

``` python
# !pip install cohere
# !pip install bertopic
import cohere
from bertopic import BERTopic
from bertopic.backend import CohereBackend
import timeit
from sklearn.datasets import fetch_20newsgroups

client = cohere.Client("PRODUCTION_API_KEY")
embedding_model = CohereBackend(client)
docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']
topic_model = BERTopic(embedding_model=embedding_model)
start_time = timeit.default_timer()
topics, probs = topic_model.fit_transform(docs)
elapsed = timeit.default_timer() - start_time
```

[Installation Guide - RAPIDS Docs](https://docs.rapids.ai/install#pip)

*GTX 1060 6Gb*

``` bash
wget https://bootstrap.pypa.io/get-pip.py
python3 get-pip.py
rm get-pip.py
sudo apt install python3-dev
sudo apt install build-essential
sudo apt install nvidia-modprobe
python3 -m pip install bertopic
```

``` python

import timeit
from bertopic import BERTopic
from sklearn.datasets import fetch_20newsgroups
topic_model = BERTopic(embedding_model="all-MiniLM-L6-v2")
docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']

# topic_model = BERTopic()
start_time = timeit.default_timer()
topics, probs = topic_model.fit_transform(docs)
elapsed = timeit.default_timer() - start_time

```
* [python - How to resolve ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects - Stack Overflow](https://stackoverflow.com/questions/73171473/how-to-resolve-error-could-not-build-wheels-for-hdbscan-which-is-required-to-i)


*GTX 3090*

#TODO


## Issues with Bertopic on ROCm

``` bash

RuntimeError: HIP error: invalid device function
HIP kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing HIP_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_HIP_DSA` to enable device-side assertions.

```


* [python - Numba needs NumPy 1.20 or less for shapley import - Stack Overflow](https://stackoverflow.com/questions/70148065/numba-needs-numpy-1-20-or-less-for-shapley-import)
* [SystemError: initialization of \_internal failed without raising an exception · openai/whisper · Discussion #1103](https://github.com/openai/whisper/discussions/1103)

#### Backlinks

* [Project Update Posts](/4c45797f-8d43-4277-a5c1-de8df9aa7876)